{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d67f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "####$ Data Definition $####\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "# training dataset \n",
    "X = np.array([[1, 1, 1], \n",
    " [3, 40, 1], \n",
    " [4, 20, 10], \n",
    " [5., 3, 1], \n",
    " [5, 3, 2], \n",
    " [6, 40, 1], \n",
    " [8, 9, 2], \n",
    " [9, 3, 4], \n",
    " [11, 100, 12] \n",
    "])\n",
    "\n",
    "\n",
    "y = np.array([10,22,28,39,50,65, 65,80,95])\n",
    "\n",
    "\n",
    "\"\"\"%\n",
    "X = np.array(XX)\n",
    "y = np.array(yy)\n",
    "%\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8184dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####$ Model Definition $####\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.callbacks import EarlyStopping,  ModelCheckpoint \n",
    "#----from delphi_training_callback import DelphiTrainingCallback----\n",
    "\n",
    "model = Sequential() \n",
    "#model.add(Input(shape=(X.shape[1],))) \n",
    "model.add(Dense(64, input_shape=(X.shape[1],)))\n",
    "model.add(Dense(units=32)) \n",
    "model.add(Dense(units=16)) \n",
    "model.add(Dense(units=1, activation='ReLU')) \n",
    "model.compile(loss='mse', optimizer=\"adam\") # , metrics =['mae', 'mape'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b80c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c41882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1834.4199 - val_loss: 5700.1387\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1723.7391 - val_loss: 5109.6914\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1621.4485 - val_loss: 4594.1216\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1527.3978 - val_loss: 4152.2173\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1441.5316 - val_loss: 3782.7712\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1363.7452 - val_loss: 3484.1133\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1293.8781 - val_loss: 3254.1584\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1231.7454 - val_loss: 3090.4585\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1177.1407 - val_loss: 2990.0708\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1129.8215 - val_loss: 2949.3423\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1089.4934 - val_loss: 2963.6741\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1055.7942 - val_loss: 3027.2471\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1028.2731 - val_loss: 3132.7224\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1006.3636 - val_loss: 3271.0266\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 989.3600 - val_loss: 3431.3711\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 976.4106 - val_loss: 3601.6387\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 966.5364 - val_loss: 3769.1467\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 958.6872 - val_loss: 3921.6865\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 951.8190 - val_loss: 4048.6484\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 944.9837 - val_loss: 4141.9468\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 937.4100 - val_loss: 4196.5928\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 928.5568 - val_loss: 4210.7891\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 918.1293 - val_loss: 4185.6274\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 906.0621 - val_loss: 4124.5371\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 892.4770 - val_loss: 4032.6011\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 877.6303 - val_loss: 3915.8811\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 861.8550 - val_loss: 3780.8047\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 845.5119 - val_loss: 3633.6587\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 828.9442 - val_loss: 3480.2224\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 812.4481 - val_loss: 3325.5100\n",
      "[5700.138671875, 5109.69140625, 4594.12158203125, 4152.21728515625, 3782.771240234375, 3484.11328125, 3254.158447265625, 3090.45849609375, 2990.07080078125, 2949.34228515625, 2963.674072265625, 3027.2470703125, 3132.722412109375, 3271.026611328125, 3431.37109375, 3601.638671875, 3769.146728515625, 3921.6865234375, 4048.6484375, 4141.94677734375, 4196.5927734375, 4210.7890625, 4185.62744140625, 4124.537109375, 4032.60107421875, 3915.881103515625, 3780.8046875, 3633.65869140625, 3480.222412109375, 3325.510009765625]\n"
     ]
    }
   ],
   "source": [
    "####$ Model Training $####\n",
    "\n",
    "callbacks = [] \n",
    "\n",
    "\"\"\"%\n",
    "callbacks.append(DelphiTrainingCallback())\n",
    "%\"\"\"\n",
    "\n",
    "callbacks.append(EarlyStopping(monitor='val_loss',  patience=20, restore_best_weights=True)) \n",
    "callbacks.append(ModelCheckpoint('my model weighs.hdf5', monitor='val_loss', save_best_only=True)) \n",
    "\n",
    "# Fit the neural model \n",
    "history=model.fit(X, y, validation_split=0.2, epochs= 100, callbacks=callbacks) \n",
    "print(history.history[\"val_loss\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c81960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [2.0507758]\n",
      "[-1, -2, -10] [-1.1975981]\n",
      "[10, 10, 10] [9.996066]\n",
      "[100, 4, 50] [5.4973865]\n"
     ]
    }
   ],
   "source": [
    "####$ Model Testing $####\n",
    "X_test = [[1, 2, 3], \n",
    " [-1, -2, -10], \n",
    " [10, 10, 10], \n",
    " [100, 4, 50] \n",
    "] \n",
    "\n",
    "Y_test = [0, 0, 0, 0]\n",
    "\n",
    "\"\"\"%\n",
    "X_test = np.array(XX_test)\n",
    "Y_test = np.array(yy_test)\n",
    "%\"\"\"\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test) \n",
    "for x, y in zip(X_test, predictions): \n",
    "    print(x, y)\n",
    "    \n",
    "    \n",
    "yy_pred = predictions.tolist()\n",
    "errors = (predictions - Y_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c921f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
